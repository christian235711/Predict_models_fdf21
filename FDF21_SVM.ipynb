{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FDF21_SVM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNVij174fIee2hu7rEoEQCX"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BsZJl8nWrTAJ",
        "outputId": "86d1c7f3-6397-4130-8061-81451f1ef973"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "\n",
        "from sklearn.metrics import f1_score, confusion_matrix, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, learning_curve, GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tIwWve5erXNe"
      },
      "source": [
        "#nombre de modalités de chaque variables (dans un dataframe)\n",
        "def nombre_mod(data2):\n",
        "    #création d'un dataframe vide\n",
        "    dff= pd.DataFrame(columns=[\"VARIABLE\",\"NOMBRE_MOD\", \"NOMBRE_MOD_SANS_NA\"])\n",
        "    for i in range(data2.shape[1]): # sans compter les valeurs manquantes\n",
        "        taille =len(data2.iloc[:,i].value_counts(dropna=False))\n",
        "        taille_1 = len(data2.iloc[:,i].value_counts(dropna=True) )\n",
        "        dff=dff.append({\"VARIABLE\": colonnes[i],\"NOMBRE_MOD\":taille, \"NOMBRE_MOD_SANS_NA\":taille_1 }, ignore_index=True)\n",
        "    return dff"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "acHEql4drXPt"
      },
      "source": [
        "# option d'affichage des résultats\n",
        "#pd.set_option(\"display.max_row\",130)\n",
        "pd.set_option(\"display.max_columns\",100)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEdAWARBthC2"
      },
      "source": [
        "# les noms des variables\n",
        "\n",
        "colonnes =([\"IDENT\", \"TypeHabi\", \"GeoFaz_Scl\", \"GeoFaz_cl\", \"ImmoFaz_Scl\", \"ImmoFaz_cl\", \"Anciennete\",\n",
        "            \"Logement_prix_m2\", \"Mediane_RFR\", \"Sexe\", \"Prenom_Phase_scl_H\", \"Prenom_Phase_scl_F\",\n",
        "            \"Prenom_Phase_cl_H\", \"Prenom_Phase_cl_F\", \"Age_H\", \"Age_F\", \"Affinite_1\", \"Affinite_2\",\n",
        "            \"Prenom_effectif\", \"Potentiel_prenom\", \"Onoma-Phase_Scl\", \"Onoma-Phase_CL\", \"Top_mon\"])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "5Qi7kaSWthE5",
        "outputId": "735825d7-6994-4690-a873-5fc2d64d0bc8"
      },
      "source": [
        "#data_orig = pd.read_csv(\"C:/Users/Christian/Desktop/my_data_FDFIFI19.txt\",sep=\" \" , names = colonnes, low_memory=False, dtype=str )#, dtype='Int64')\n",
        "data_orig = pd.read_csv(\"/content/drive/MyDrive/spad_score_method_1/spad_projection_FDFTOT21/my_data_FDFTOT21.txt\", delim_whitespace=\"\\t\", header = None, names=colonnes, low_memory=False, dtype=str )#, dtype='Int64')\n",
        "data_orig\n",
        "data = data_orig.copy()\n",
        "data"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IDENT</th>\n",
              "      <th>TypeHabi</th>\n",
              "      <th>GeoFaz_Scl</th>\n",
              "      <th>GeoFaz_cl</th>\n",
              "      <th>ImmoFaz_Scl</th>\n",
              "      <th>ImmoFaz_cl</th>\n",
              "      <th>Anciennete</th>\n",
              "      <th>Logement_prix_m2</th>\n",
              "      <th>Mediane_RFR</th>\n",
              "      <th>Sexe</th>\n",
              "      <th>Prenom_Phase_scl_H</th>\n",
              "      <th>Prenom_Phase_scl_F</th>\n",
              "      <th>Prenom_Phase_cl_H</th>\n",
              "      <th>Prenom_Phase_cl_F</th>\n",
              "      <th>Age_H</th>\n",
              "      <th>Age_F</th>\n",
              "      <th>Affinite_1</th>\n",
              "      <th>Affinite_2</th>\n",
              "      <th>Prenom_effectif</th>\n",
              "      <th>Potentiel_prenom</th>\n",
              "      <th>Onoma-Phase_Scl</th>\n",
              "      <th>Onoma-Phase_CL</th>\n",
              "      <th>Top_mon</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000000010010000001</td>\n",
              "      <td>02</td>\n",
              "      <td>81</td>\n",
              "      <td>08</td>\n",
              "      <td>91</td>\n",
              "      <td>09</td>\n",
              "      <td>06</td>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "      <td>01</td>\n",
              "      <td>71</td>\n",
              "      <td>41</td>\n",
              "      <td>07</td>\n",
              "      <td>04</td>\n",
              "      <td>12</td>\n",
              "      <td>04</td>\n",
              "      <td>20</td>\n",
              "      <td>02</td>\n",
              "      <td>02</td>\n",
              "      <td>01</td>\n",
              "      <td>51</td>\n",
              "      <td>05</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000000020010000006</td>\n",
              "      <td>01</td>\n",
              "      <td>75</td>\n",
              "      <td>07</td>\n",
              "      <td>43</td>\n",
              "      <td>04</td>\n",
              "      <td>06</td>\n",
              "      <td>06</td>\n",
              "      <td>13</td>\n",
              "      <td>02</td>\n",
              "      <td>71</td>\n",
              "      <td>64</td>\n",
              "      <td>07</td>\n",
              "      <td>06</td>\n",
              "      <td>12</td>\n",
              "      <td>09</td>\n",
              "      <td>04</td>\n",
              "      <td>12</td>\n",
              "      <td>04</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>01</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000000030010000011</td>\n",
              "      <td>01</td>\n",
              "      <td>76</td>\n",
              "      <td>07</td>\n",
              "      <td>43</td>\n",
              "      <td>04</td>\n",
              "      <td>06</td>\n",
              "      <td>06</td>\n",
              "      <td>16</td>\n",
              "      <td>03</td>\n",
              "      <td>54</td>\n",
              "      <td>81</td>\n",
              "      <td>05</td>\n",
              "      <td>08</td>\n",
              "      <td>07</td>\n",
              "      <td>12</td>\n",
              "      <td>06</td>\n",
              "      <td>06</td>\n",
              "      <td>04</td>\n",
              "      <td>18</td>\n",
              "      <td>36</td>\n",
              "      <td>03</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000000040010000013</td>\n",
              "      <td>03</td>\n",
              "      <td>75</td>\n",
              "      <td>07</td>\n",
              "      <td>43</td>\n",
              "      <td>04</td>\n",
              "      <td>04</td>\n",
              "      <td>06</td>\n",
              "      <td>13</td>\n",
              "      <td>01</td>\n",
              "      <td>71</td>\n",
              "      <td>36</td>\n",
              "      <td>07</td>\n",
              "      <td>03</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>19</td>\n",
              "      <td>04</td>\n",
              "      <td>06</td>\n",
              "      <td>21</td>\n",
              "      <td>02</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000000050010000015</td>\n",
              "      <td>02</td>\n",
              "      <td>33</td>\n",
              "      <td>03</td>\n",
              "      <td>44</td>\n",
              "      <td>04</td>\n",
              "      <td>06</td>\n",
              "      <td>07</td>\n",
              "      <td>12</td>\n",
              "      <td>01</td>\n",
              "      <td>71</td>\n",
              "      <td>42</td>\n",
              "      <td>07</td>\n",
              "      <td>04</td>\n",
              "      <td>12</td>\n",
              "      <td>05</td>\n",
              "      <td>14</td>\n",
              "      <td>03</td>\n",
              "      <td>03</td>\n",
              "      <td>01</td>\n",
              "      <td>14</td>\n",
              "      <td>01</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1219994</th>\n",
              "      <td>010928800370109343</td>\n",
              "      <td>01</td>\n",
              "      <td>64</td>\n",
              "      <td>06</td>\n",
              "      <td>82</td>\n",
              "      <td>08</td>\n",
              "      <td>05</td>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>02</td>\n",
              "      <td>71</td>\n",
              "      <td>81</td>\n",
              "      <td>07</td>\n",
              "      <td>08</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "      <td>06</td>\n",
              "      <td>21</td>\n",
              "      <td>61</td>\n",
              "      <td>06</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1219995</th>\n",
              "      <td>010928810370109344</td>\n",
              "      <td>03</td>\n",
              "      <td>61</td>\n",
              "      <td>06</td>\n",
              "      <td>64</td>\n",
              "      <td>06</td>\n",
              "      <td>06</td>\n",
              "      <td>14</td>\n",
              "      <td>01</td>\n",
              "      <td>04</td>\n",
              "      <td>44</td>\n",
              "      <td>81</td>\n",
              "      <td>04</td>\n",
              "      <td>08</td>\n",
              "      <td>05</td>\n",
              "      <td>12</td>\n",
              "      <td>01</td>\n",
              "      <td>05</td>\n",
              "      <td>01</td>\n",
              "      <td>03</td>\n",
              "      <td>54</td>\n",
              "      <td>05</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1219996</th>\n",
              "      <td>010928820370109345</td>\n",
              "      <td>02</td>\n",
              "      <td>13</td>\n",
              "      <td>01</td>\n",
              "      <td>42</td>\n",
              "      <td>04</td>\n",
              "      <td>07</td>\n",
              "      <td>07</td>\n",
              "      <td>15</td>\n",
              "      <td>02</td>\n",
              "      <td>71</td>\n",
              "      <td>81</td>\n",
              "      <td>07</td>\n",
              "      <td>08</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "      <td>06</td>\n",
              "      <td>21</td>\n",
              "      <td>61</td>\n",
              "      <td>06</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1219997</th>\n",
              "      <td>010928830370109346</td>\n",
              "      <td>02</td>\n",
              "      <td>31</td>\n",
              "      <td>03</td>\n",
              "      <td>82</td>\n",
              "      <td>08</td>\n",
              "      <td>08</td>\n",
              "      <td>16</td>\n",
              "      <td>19</td>\n",
              "      <td>02</td>\n",
              "      <td>71</td>\n",
              "      <td>45</td>\n",
              "      <td>07</td>\n",
              "      <td>04</td>\n",
              "      <td>12</td>\n",
              "      <td>03</td>\n",
              "      <td>02</td>\n",
              "      <td>02</td>\n",
              "      <td>03</td>\n",
              "      <td>01</td>\n",
              "      <td>44</td>\n",
              "      <td>04</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1219998</th>\n",
              "      <td>010928840370109347</td>\n",
              "      <td>02</td>\n",
              "      <td>12</td>\n",
              "      <td>01</td>\n",
              "      <td>82</td>\n",
              "      <td>08</td>\n",
              "      <td>06</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>03</td>\n",
              "      <td>33</td>\n",
              "      <td>81</td>\n",
              "      <td>03</td>\n",
              "      <td>08</td>\n",
              "      <td>07</td>\n",
              "      <td>12</td>\n",
              "      <td>03</td>\n",
              "      <td>03</td>\n",
              "      <td>05</td>\n",
              "      <td>20</td>\n",
              "      <td>31</td>\n",
              "      <td>03</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1219999 rows × 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      IDENT TypeHabi GeoFaz_Scl GeoFaz_cl ImmoFaz_Scl  \\\n",
              "0        000000010010000001       02         81        08          91   \n",
              "1        000000020010000006       01         75        07          43   \n",
              "2        000000030010000011       01         76        07          43   \n",
              "3        000000040010000013       03         75        07          43   \n",
              "4        000000050010000015       02         33        03          44   \n",
              "...                     ...      ...        ...       ...         ...   \n",
              "1219994  010928800370109343       01         64        06          82   \n",
              "1219995  010928810370109344       03         61        06          64   \n",
              "1219996  010928820370109345       02         13        01          42   \n",
              "1219997  010928830370109346       02         31        03          82   \n",
              "1219998  010928840370109347       02         12        01          82   \n",
              "\n",
              "        ImmoFaz_cl Anciennete Logement_prix_m2 Mediane_RFR Sexe  \\\n",
              "0               09         06               21          21   01   \n",
              "1               04         06               06          13   02   \n",
              "2               04         06               06          16   03   \n",
              "3               04         04               06          13   01   \n",
              "4               04         06               07          12   01   \n",
              "...            ...        ...              ...         ...  ...   \n",
              "1219994         08         05               16          17   02   \n",
              "1219995         06         06               14          01   04   \n",
              "1219996         04         07               07          15   02   \n",
              "1219997         08         08               16          19   02   \n",
              "1219998         08         06               17          17   03   \n",
              "\n",
              "        Prenom_Phase_scl_H Prenom_Phase_scl_F Prenom_Phase_cl_H  \\\n",
              "0                       71                 41                07   \n",
              "1                       71                 64                07   \n",
              "2                       54                 81                05   \n",
              "3                       71                 36                07   \n",
              "4                       71                 42                07   \n",
              "...                    ...                ...               ...   \n",
              "1219994                 71                 81                07   \n",
              "1219995                 44                 81                04   \n",
              "1219996                 71                 81                07   \n",
              "1219997                 71                 45                07   \n",
              "1219998                 33                 81                03   \n",
              "\n",
              "        Prenom_Phase_cl_F Age_H Age_F Affinite_1 Affinite_2 Prenom_effectif  \\\n",
              "0                      04    12    04         20         02              02   \n",
              "1                      06    12    09         04         12              04   \n",
              "2                      08    07    12         06         06              04   \n",
              "3                      03    12    11         11         19              04   \n",
              "4                      04    12    05         14         03              03   \n",
              "...                   ...   ...   ...        ...        ...             ...   \n",
              "1219994                08    12    12         21         21              06   \n",
              "1219995                08    05    12         01         05              01   \n",
              "1219996                08    12    12         21         21              06   \n",
              "1219997                04    12    03         02         02              03   \n",
              "1219998                08    07    12         03         03              05   \n",
              "\n",
              "        Potentiel_prenom Onoma-Phase_Scl Onoma-Phase_CL Top_mon  \n",
              "0                     01              51             05       1  \n",
              "1                     13              12             01       1  \n",
              "2                     18              36             03       2  \n",
              "3                     06              21             02       1  \n",
              "4                     01              14             01       2  \n",
              "...                  ...             ...            ...     ...  \n",
              "1219994               21              61             06     NaN  \n",
              "1219995               03              54             05     NaN  \n",
              "1219996               21              61             06     NaN  \n",
              "1219997               01              44             04     NaN  \n",
              "1219998               20              31             03     NaN  \n",
              "\n",
              "[1219999 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4X2PFkWytrku"
      },
      "source": [
        "# sélection des corrélations les plus importantes\n",
        "def variables_corr(tableau_corr, seuil):\n",
        "    variables_corr_pos=[] ; variables_corr_pos_val=[]\n",
        "    variables_corr_neg=[] ; variables_corr_neg_val=[]\n",
        "    for i in range(tableau_corr.shape[0]):  \n",
        "        for j in range(tableau_corr.shape[0]):\n",
        "            if i<j: #i!=j:\n",
        "                if (tableau_corr.iloc[i,j] > seuil):\n",
        "                    variables_corr_pos.append(colonnes[j+1])\n",
        "                    variables_corr_pos_val.append(round( tableau_corr.iloc[i,j], 2))\n",
        "                if (tableau_corr.iloc[i,j] <-seuil):\n",
        "                    variables_corr_neg.append(colonnes[j+1])\n",
        "                    variables_corr_neg_val.append(round( tableau_corr.iloc[i,j], 2))\n",
        "\n",
        "        if (len(variables_corr_pos) > 0) | (len(variables_corr_neg) >0) :\n",
        "            print(\"variable : \", colonnes[i+1])\n",
        "            if len(variables_corr_pos) > 0:    \n",
        "                print(\"corr pos\", variables_corr_pos)\n",
        "                print(\"corr pos\", variables_corr_pos_val)\n",
        "            if len(variables_corr_neg) >0:  \n",
        "                print(\"corr neg\", variables_corr_neg)\n",
        "                print(\"corr neg\", variables_corr_neg_val)\n",
        "            print(\"\")\n",
        "        variables_corr_pos = variables_corr_pos*0\n",
        "        variables_corr_neg = variables_corr_pos*0\n",
        "\n",
        "        variables_corr_pos_val = variables_corr_pos_val*0\n",
        "        variables_corr_neg_val = variables_corr_pos_val*0\n",
        "        \n",
        "# élimination des variables trop corrélées (choix manuel)\n",
        "def elimination_val_corr(data):\n",
        "    data = data.drop(columns=[\"GeoFaz_cl\",\"Prenom_Phase_cl_H\",\"Prenom_Phase_cl_F\"])\n",
        "    return data\n",
        "          "
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jBqiGxJCtrm9"
      },
      "source": [
        "# Comme il n'y a pas de valeurs manquantes, le seul traitement qu'on fait c'est tranformer\n",
        "# le type de variable (les variables continues deviennent qualitatives)\n",
        "def data_processing(df):\n",
        "    \"\"\" \n",
        "    for i in range(0,len(df.columns)):    \n",
        "        df[df.columns[i]].fillna(100.0, inplace=True) #On remplace les données manquantes par 100\n",
        "    for i in range(0,len(df.columns)):\n",
        "        print(df[df.columns[i]].value_counts(dropna=False))    \n",
        "    \"\"\"\n",
        "    \n",
        "   #Transformation de toutes les variables en facteurs         \n",
        "    for i in range(0,len(df.columns)):\n",
        "        df[df.columns[i]] = df[df.columns[i]].astype('category')\n",
        "    return df.to_numpy() \n"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Sc4uZ8jtro2"
      },
      "source": [
        "\n",
        "def evaluation(model, X_train, y_train, X_test, y_test, scoring, plot):\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    print(\"test set : \")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(classification_report(y_test, y_pred)) \n",
        "    print(\"train set : \")\n",
        "    print(confusion_matrix(y_train, model.predict(X_train))) # ajouter \n",
        "    print(classification_report(y_train, model.predict(X_train) ))\n",
        "\n",
        "    if plot == True :\n",
        "        N, train_score, val_score = learning_curve(model, X_train, y_train, cv = 4,shuffle=True, scoring = scoring, train_sizes = np.linspace(0.1, 1, 6) )\n",
        "        #print(N)\n",
        "        #print(train_score.mean(axis=1))\n",
        "        plt.figure(figsize = (10,6))\n",
        "        plt.plot(N, train_score.mean(axis=1), label =\"train_score\")\n",
        "        plt.plot(N, val_score.mean(axis=1), label =\"cross_validation_score\")\n",
        "        plt.legend()\n",
        "    else:\n",
        "        print(\"AFFICHAGE NON DEMANDE\")\n",
        "    \n",
        "def quarantiles(model, data_orig, affichage, save, path):\n",
        "    # position de la dernière variable explicative dans le dataset\n",
        "    nb_var = data_orig.shape[1]-1\n",
        "    \n",
        "    # predict sur tous les individus (avec et sans classe IFI+)\n",
        "    tous_probas = model.predict_proba(data_orig.iloc[:,1:nb_var])\n",
        "    df_tous = pd.DataFrame({'IDENT': data_orig.iloc[:,0] , 'PROBA': tous_probas[:,0] })\n",
        "    #df_tous\n",
        "\n",
        "    # valeurs ordonnées pour diviser après\n",
        "    df_tous=df_tous.sort_values(by='PROBA', ascending=True)\n",
        "    #df_tous\n",
        "\n",
        "    # vérification\n",
        "    print(df_tous['PROBA'].value_counts())\n",
        "    \n",
        "    # quarantiles\n",
        "    df_temp =pd.DataFrame( pd.qcut(df_tous['PROBA'],q= 20)  )\n",
        "    # ajout par index (IMPORTANTE)\n",
        "    df_tous[\"TRANCHES\"]=pd.DataFrame(df_temp.iloc[:,0].to_numpy(),index= df_temp.index)\n",
        "    #df_tous\n",
        "\n",
        "    # pour la colonne IFI+ :\n",
        "    # remplissage de la dernière colonne par 2 (VALABLE QUE POUR CE DATA, MODIFIER POUR D'AUTRES)\n",
        "    data_temp_t = data_orig.copy()\n",
        "    # remplacement\n",
        "    data_temp_t[\"Top_mon\"] =  data_temp_t[\"Top_mon\"].replace(1.0,'1')\n",
        "    data_temp_t[\"Top_mon\"] =  data_temp_t[\"Top_mon\"].replace(2.0,'2')\n",
        "    data_all_complet_class = data_temp_t.fillna('2')\n",
        "    #data_all_complet_class\n",
        "\n",
        "    # jointure\n",
        "    ident_class_tous = data_all_complet_class[[\"IDENT\",\"Top_mon\"]]\n",
        "    tableau_resultats = pd.merge(df_tous,ident_class_tous)\n",
        "    #tableau_resultats\n",
        "\n",
        "    # tranches finales\n",
        "    tab_cross_temp = pd.crosstab(tableau_resultats[\"TRANCHES\"],tableau_resultats[\"Top_mon\"])    \n",
        "    \n",
        "    # création d'une colonne total\n",
        "    tab_cross_temp[\"TOTAL\"]=tab_cross_temp[\"1\"]+tab_cross_temp[\"2\"]\n",
        "    \n",
        "    # affichage\n",
        "    if affichage ==True:        \n",
        "        print(tab_cross_temp)\n",
        "    \n",
        "    # création du tableau final en éliminant la colonne 2\n",
        "    tab_pour_excel = tab_cross_temp.drop([\"2\"], axis=1)\n",
        "    \n",
        "    # enregistrement sous Excel\n",
        "    if save == True:\n",
        "        tab_pour_excel.to_excel(path)\n",
        "\n",
        "     "
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfyUkn9rthHd"
      },
      "source": [
        "####################################################################################\n",
        "#                                 PREMIERS TESTS\n",
        "####################################################################################\n"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwLaUOkUyyIG"
      },
      "source": [
        "##########################################\n",
        "# AVEC TOUTES LES VARIABLES  ET ENCODAGE DUMMIES\n",
        "#########################################"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ED1X5uh9rXSQ",
        "outputId": "f815dee2-1965-4b6e-de6f-1b288363ffb5"
      },
      "source": [
        "# test predict individus sans classe\n",
        "data = data_orig.copy()\n",
        "\n",
        "# encodage Onehot sur toutes les données (on évite ainsi les erreurs futures)\n",
        "nb_var = data.shape[1] - 1\n",
        "data_1_22 = pd.get_dummies(data.iloc[:,1:(data.shape[1]-1)], columns=data.columns[1:(data.shape[1]-1)] )\n",
        "data_var_qualitatives_temp =  pd.concat([data[\"IDENT\"], data_1_22, data[\"Top_mon\"]], axis=1)\n",
        "data = data_var_qualitatives_temp\n",
        "#encodage = OneHotEncoder()\n",
        "#encodage.fit(data_processing(data.iloc[:,1:nb_var]))\n",
        "\n",
        "# élimination des individus n'ayant pas de valeur pour la varialbe IFI+\n",
        "\"\"\"IMPORTANT\"\"\"\n",
        "data_sans_nan = data[(data.isnull()).sum(axis=1) == 0]\n",
        "\n",
        "#conversion du type de variable\n",
        "for i in range(1,data_sans_nan.shape[1]):\n",
        "    data_sans_nan.iloc[:,i]=data_sans_nan.iloc[:,i].astype(int)\n",
        "\n",
        "# base de données avec des variables corrélées et avec encodage OneHot\n",
        "data =data_sans_nan\n",
        "\n",
        "nb_var = data.shape[1] - 1\n",
        "train_set, test_set = train_test_split(data, test_size = 0.2, random_state=0 )\n",
        "\n",
        "train_X_s = (train_set.iloc[:,1:nb_var]).to_numpy()\n",
        "train_Y_s = np.asanyarray(train_set.iloc[:,nb_var])\n",
        "\n",
        "test_X_s = (test_set.iloc[:,1:nb_var]).to_numpy()\n",
        "test_Y_s = np.asanyarray(test_set.iloc[:,nb_var])\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(ilocs[0], value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YDQLTzs_t7lG",
        "outputId": "b147cd8c-34e8-4eeb-e94d-c650eb9f2082"
      },
      "source": [
        "model_LinearSVC = LinearSVC(class_weight =\"balanced\", random_state =0 )\n",
        "param = { \"penalty\": [\"l1\", \"l2\"], \"C\":[0.001, 0.01,0.1, 0.5,1, 1.5, 2, 10 ], \"loss\":[\"hinge\", \"squared_hinge\"] }\n",
        "\n",
        "grid_LinearSVC = GridSearchCV(model_LinearSVC, param, cv = 4, scoring = \"recall\")\n",
        "resultat_grid_LinearSVC = grid_LinearSVC.fit(train_X_s, train_Y_s)\n",
        "resultat_grid_LinearSVC.best_params_\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='hinge' is not supported, Parameters: penalty='l1', loss='hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Unsupported set of arguments: The combination of penalty='l1' and loss='squared_hinge' are not supported when dual=True, Parameters: penalty='l1', loss='squared_hinge', dual=True\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/svm/_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
            "  \"the number of iterations.\", ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 0.001, 'loss': 'squared_hinge', 'penalty': 'l2'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0h8JjZCBt7nH",
        "outputId": "9efbf423-3304-479f-bcd6-9a80dd0e5bcf"
      },
      "source": [
        "final_model_LinearSVC = LinearSVC(C=0.001, penalty='l2', loss= 'squared_hinge', class_weight =\"balanced\", random_state=0 ) \n",
        "evaluation(final_model_LinearSVC, train_X_s, train_Y_s, test_X_s, test_Y_s, scoring=\"recall\", plot=False)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test set : \n",
            "[[ 2506  2173]\n",
            " [ 7446 13298]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.25      0.54      0.34      4679\n",
            "           2       0.86      0.64      0.73     20744\n",
            "\n",
            "    accuracy                           0.62     25423\n",
            "   macro avg       0.56      0.59      0.54     25423\n",
            "weighted avg       0.75      0.62      0.66     25423\n",
            "\n",
            "train set : \n",
            "[[10396  8381]\n",
            " [29069 53846]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.26      0.55      0.36     18777\n",
            "           2       0.87      0.65      0.74     82915\n",
            "\n",
            "    accuracy                           0.63    101692\n",
            "   macro avg       0.56      0.60      0.55    101692\n",
            "weighted avg       0.75      0.63      0.67    101692\n",
            "\n",
            "AFFICHAGE NON DEMANDE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHB1a9aAzwbc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyadTnENzwd9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3WYrLcgzwgI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}