{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "FDF21_logistic_regression_quali.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "46d1b569",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f8e17f6-2c17-48b1-cf9c-5b26267b32f7"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import sklearn\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from sklearn.metrics import f1_score, confusion_matrix, classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split, learning_curve, GridSearchCV, RandomizedSearchCV\n",
        "\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "46d1b569",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzxckN1fQpZU"
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "id": "CzxckN1fQpZU",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d704d0bf"
      },
      "source": [
        "# option d'affichage des r√©sultats\n",
        "#pd.set_option(\"display.max_row\",130)\n",
        "pd.set_option(\"display.max_columns\",100)"
      ],
      "id": "d704d0bf",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78ad0a9b"
      },
      "source": [
        "# les noms des variables\n",
        "\n",
        "colonnes =([\"IDENT\", \"TypeHabi\", \"GeoFaz_Scl\", \"GeoFaz_cl\", \"ImmoFaz_Scl\", \"ImmoFaz_cl\", \"Anciennete\",\n",
        "            \"Logement_prix_m2\", \"Mediane_RFR\", \"Sexe\", \"Prenom_Phase_scl_H\", \"Prenom_Phase_scl_F\",\n",
        "            \"Prenom_Phase_cl_H\", \"Prenom_Phase_cl_F\", \"Age_H\", \"Age_F\", \"Affinite_1\", \"Affinite_2\",\n",
        "            \"Prenom_effectif\", \"Potentiel_prenom\", \"Onoma-Phase_Scl\", \"Onoma-Phase_CL\", \"Top_mon\"])"
      ],
      "id": "78ad0a9b",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "47c00091",
        "outputId": "4f557309-282b-4169-c6e4-6f657c098497"
      },
      "source": [
        "#data_orig = pd.read_csv(\"C:/Users/Christian/Desktop/my_data_FDFIFI19.txt\",sep=\" \" , names = colonnes, low_memory=False, dtype=str )#, dtype='Int64')\n",
        "data_orig = pd.read_csv(\"/content/drive/MyDrive/spad_score_method_1/spad_projection_FDFTOT21/my_data_FDFTOT21.txt\", delim_whitespace=\"\\t\", header = None, names=colonnes, low_memory=False, dtype=str )#, dtype='Int64')\n",
        "data = data_orig.copy()\n",
        "data"
      ],
      "id": "47c00091",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IDENT</th>\n",
              "      <th>TypeHabi</th>\n",
              "      <th>GeoFaz_Scl</th>\n",
              "      <th>GeoFaz_cl</th>\n",
              "      <th>ImmoFaz_Scl</th>\n",
              "      <th>ImmoFaz_cl</th>\n",
              "      <th>Anciennete</th>\n",
              "      <th>Logement_prix_m2</th>\n",
              "      <th>Mediane_RFR</th>\n",
              "      <th>Sexe</th>\n",
              "      <th>Prenom_Phase_scl_H</th>\n",
              "      <th>Prenom_Phase_scl_F</th>\n",
              "      <th>Prenom_Phase_cl_H</th>\n",
              "      <th>Prenom_Phase_cl_F</th>\n",
              "      <th>Age_H</th>\n",
              "      <th>Age_F</th>\n",
              "      <th>Affinite_1</th>\n",
              "      <th>Affinite_2</th>\n",
              "      <th>Prenom_effectif</th>\n",
              "      <th>Potentiel_prenom</th>\n",
              "      <th>Onoma-Phase_Scl</th>\n",
              "      <th>Onoma-Phase_CL</th>\n",
              "      <th>Top_mon</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>000000010010000001</td>\n",
              "      <td>02</td>\n",
              "      <td>81</td>\n",
              "      <td>08</td>\n",
              "      <td>91</td>\n",
              "      <td>09</td>\n",
              "      <td>06</td>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "      <td>01</td>\n",
              "      <td>71</td>\n",
              "      <td>41</td>\n",
              "      <td>07</td>\n",
              "      <td>04</td>\n",
              "      <td>12</td>\n",
              "      <td>04</td>\n",
              "      <td>20</td>\n",
              "      <td>02</td>\n",
              "      <td>02</td>\n",
              "      <td>01</td>\n",
              "      <td>51</td>\n",
              "      <td>05</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000000020010000006</td>\n",
              "      <td>01</td>\n",
              "      <td>75</td>\n",
              "      <td>07</td>\n",
              "      <td>43</td>\n",
              "      <td>04</td>\n",
              "      <td>06</td>\n",
              "      <td>06</td>\n",
              "      <td>13</td>\n",
              "      <td>02</td>\n",
              "      <td>71</td>\n",
              "      <td>64</td>\n",
              "      <td>07</td>\n",
              "      <td>06</td>\n",
              "      <td>12</td>\n",
              "      <td>09</td>\n",
              "      <td>04</td>\n",
              "      <td>12</td>\n",
              "      <td>04</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>01</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000000030010000011</td>\n",
              "      <td>01</td>\n",
              "      <td>76</td>\n",
              "      <td>07</td>\n",
              "      <td>43</td>\n",
              "      <td>04</td>\n",
              "      <td>06</td>\n",
              "      <td>06</td>\n",
              "      <td>16</td>\n",
              "      <td>03</td>\n",
              "      <td>54</td>\n",
              "      <td>81</td>\n",
              "      <td>05</td>\n",
              "      <td>08</td>\n",
              "      <td>07</td>\n",
              "      <td>12</td>\n",
              "      <td>06</td>\n",
              "      <td>06</td>\n",
              "      <td>04</td>\n",
              "      <td>18</td>\n",
              "      <td>36</td>\n",
              "      <td>03</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000000040010000013</td>\n",
              "      <td>03</td>\n",
              "      <td>75</td>\n",
              "      <td>07</td>\n",
              "      <td>43</td>\n",
              "      <td>04</td>\n",
              "      <td>04</td>\n",
              "      <td>06</td>\n",
              "      <td>13</td>\n",
              "      <td>01</td>\n",
              "      <td>71</td>\n",
              "      <td>36</td>\n",
              "      <td>07</td>\n",
              "      <td>03</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>19</td>\n",
              "      <td>04</td>\n",
              "      <td>06</td>\n",
              "      <td>21</td>\n",
              "      <td>02</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>000000050010000015</td>\n",
              "      <td>02</td>\n",
              "      <td>33</td>\n",
              "      <td>03</td>\n",
              "      <td>44</td>\n",
              "      <td>04</td>\n",
              "      <td>06</td>\n",
              "      <td>07</td>\n",
              "      <td>12</td>\n",
              "      <td>01</td>\n",
              "      <td>71</td>\n",
              "      <td>42</td>\n",
              "      <td>07</td>\n",
              "      <td>04</td>\n",
              "      <td>12</td>\n",
              "      <td>05</td>\n",
              "      <td>14</td>\n",
              "      <td>03</td>\n",
              "      <td>03</td>\n",
              "      <td>01</td>\n",
              "      <td>14</td>\n",
              "      <td>01</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1219994</th>\n",
              "      <td>010928800370109343</td>\n",
              "      <td>01</td>\n",
              "      <td>64</td>\n",
              "      <td>06</td>\n",
              "      <td>82</td>\n",
              "      <td>08</td>\n",
              "      <td>05</td>\n",
              "      <td>16</td>\n",
              "      <td>17</td>\n",
              "      <td>02</td>\n",
              "      <td>71</td>\n",
              "      <td>81</td>\n",
              "      <td>07</td>\n",
              "      <td>08</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "      <td>06</td>\n",
              "      <td>21</td>\n",
              "      <td>61</td>\n",
              "      <td>06</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1219995</th>\n",
              "      <td>010928810370109344</td>\n",
              "      <td>03</td>\n",
              "      <td>61</td>\n",
              "      <td>06</td>\n",
              "      <td>64</td>\n",
              "      <td>06</td>\n",
              "      <td>06</td>\n",
              "      <td>14</td>\n",
              "      <td>01</td>\n",
              "      <td>04</td>\n",
              "      <td>44</td>\n",
              "      <td>81</td>\n",
              "      <td>04</td>\n",
              "      <td>08</td>\n",
              "      <td>05</td>\n",
              "      <td>12</td>\n",
              "      <td>01</td>\n",
              "      <td>05</td>\n",
              "      <td>01</td>\n",
              "      <td>03</td>\n",
              "      <td>54</td>\n",
              "      <td>05</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1219996</th>\n",
              "      <td>010928820370109345</td>\n",
              "      <td>02</td>\n",
              "      <td>13</td>\n",
              "      <td>01</td>\n",
              "      <td>42</td>\n",
              "      <td>04</td>\n",
              "      <td>07</td>\n",
              "      <td>07</td>\n",
              "      <td>15</td>\n",
              "      <td>02</td>\n",
              "      <td>71</td>\n",
              "      <td>81</td>\n",
              "      <td>07</td>\n",
              "      <td>08</td>\n",
              "      <td>12</td>\n",
              "      <td>12</td>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "      <td>06</td>\n",
              "      <td>21</td>\n",
              "      <td>61</td>\n",
              "      <td>06</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1219997</th>\n",
              "      <td>010928830370109346</td>\n",
              "      <td>02</td>\n",
              "      <td>31</td>\n",
              "      <td>03</td>\n",
              "      <td>82</td>\n",
              "      <td>08</td>\n",
              "      <td>08</td>\n",
              "      <td>16</td>\n",
              "      <td>19</td>\n",
              "      <td>02</td>\n",
              "      <td>71</td>\n",
              "      <td>45</td>\n",
              "      <td>07</td>\n",
              "      <td>04</td>\n",
              "      <td>12</td>\n",
              "      <td>03</td>\n",
              "      <td>02</td>\n",
              "      <td>02</td>\n",
              "      <td>03</td>\n",
              "      <td>01</td>\n",
              "      <td>44</td>\n",
              "      <td>04</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1219998</th>\n",
              "      <td>010928840370109347</td>\n",
              "      <td>02</td>\n",
              "      <td>12</td>\n",
              "      <td>01</td>\n",
              "      <td>82</td>\n",
              "      <td>08</td>\n",
              "      <td>06</td>\n",
              "      <td>17</td>\n",
              "      <td>17</td>\n",
              "      <td>03</td>\n",
              "      <td>33</td>\n",
              "      <td>81</td>\n",
              "      <td>03</td>\n",
              "      <td>08</td>\n",
              "      <td>07</td>\n",
              "      <td>12</td>\n",
              "      <td>03</td>\n",
              "      <td>03</td>\n",
              "      <td>05</td>\n",
              "      <td>20</td>\n",
              "      <td>31</td>\n",
              "      <td>03</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1219999 rows √ó 23 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                      IDENT TypeHabi GeoFaz_Scl GeoFaz_cl ImmoFaz_Scl  \\\n",
              "0        000000010010000001       02         81        08          91   \n",
              "1        000000020010000006       01         75        07          43   \n",
              "2        000000030010000011       01         76        07          43   \n",
              "3        000000040010000013       03         75        07          43   \n",
              "4        000000050010000015       02         33        03          44   \n",
              "...                     ...      ...        ...       ...         ...   \n",
              "1219994  010928800370109343       01         64        06          82   \n",
              "1219995  010928810370109344       03         61        06          64   \n",
              "1219996  010928820370109345       02         13        01          42   \n",
              "1219997  010928830370109346       02         31        03          82   \n",
              "1219998  010928840370109347       02         12        01          82   \n",
              "\n",
              "        ImmoFaz_cl Anciennete Logement_prix_m2 Mediane_RFR Sexe  \\\n",
              "0               09         06               21          21   01   \n",
              "1               04         06               06          13   02   \n",
              "2               04         06               06          16   03   \n",
              "3               04         04               06          13   01   \n",
              "4               04         06               07          12   01   \n",
              "...            ...        ...              ...         ...  ...   \n",
              "1219994         08         05               16          17   02   \n",
              "1219995         06         06               14          01   04   \n",
              "1219996         04         07               07          15   02   \n",
              "1219997         08         08               16          19   02   \n",
              "1219998         08         06               17          17   03   \n",
              "\n",
              "        Prenom_Phase_scl_H Prenom_Phase_scl_F Prenom_Phase_cl_H  \\\n",
              "0                       71                 41                07   \n",
              "1                       71                 64                07   \n",
              "2                       54                 81                05   \n",
              "3                       71                 36                07   \n",
              "4                       71                 42                07   \n",
              "...                    ...                ...               ...   \n",
              "1219994                 71                 81                07   \n",
              "1219995                 44                 81                04   \n",
              "1219996                 71                 81                07   \n",
              "1219997                 71                 45                07   \n",
              "1219998                 33                 81                03   \n",
              "\n",
              "        Prenom_Phase_cl_F Age_H Age_F Affinite_1 Affinite_2 Prenom_effectif  \\\n",
              "0                      04    12    04         20         02              02   \n",
              "1                      06    12    09         04         12              04   \n",
              "2                      08    07    12         06         06              04   \n",
              "3                      03    12    11         11         19              04   \n",
              "4                      04    12    05         14         03              03   \n",
              "...                   ...   ...   ...        ...        ...             ...   \n",
              "1219994                08    12    12         21         21              06   \n",
              "1219995                08    05    12         01         05              01   \n",
              "1219996                08    12    12         21         21              06   \n",
              "1219997                04    12    03         02         02              03   \n",
              "1219998                08    07    12         03         03              05   \n",
              "\n",
              "        Potentiel_prenom Onoma-Phase_Scl Onoma-Phase_CL Top_mon  \n",
              "0                     01              51             05       1  \n",
              "1                     13              12             01       1  \n",
              "2                     18              36             03       2  \n",
              "3                     06              21             02       1  \n",
              "4                     01              14             01       2  \n",
              "...                  ...             ...            ...     ...  \n",
              "1219994               21              61             06     NaN  \n",
              "1219995               03              54             05     NaN  \n",
              "1219996               21              61             06     NaN  \n",
              "1219997               01              44             04     NaN  \n",
              "1219998               20              31             03     NaN  \n",
              "\n",
              "[1219999 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0924d2aa",
        "outputId": "9d90ae14-49ad-4750-8845-f16f3f50d4b6"
      },
      "source": [
        "data.info()"
      ],
      "id": "0924d2aa",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1219999 entries, 0 to 1219998\n",
            "Data columns (total 23 columns):\n",
            " #   Column              Non-Null Count    Dtype \n",
            "---  ------              --------------    ----- \n",
            " 0   IDENT               1219999 non-null  object\n",
            " 1   TypeHabi            1219999 non-null  object\n",
            " 2   GeoFaz_Scl          1219999 non-null  object\n",
            " 3   GeoFaz_cl           1219999 non-null  object\n",
            " 4   ImmoFaz_Scl         1219999 non-null  object\n",
            " 5   ImmoFaz_cl          1219999 non-null  object\n",
            " 6   Anciennete          1219999 non-null  object\n",
            " 7   Logement_prix_m2    1219999 non-null  object\n",
            " 8   Mediane_RFR         1219999 non-null  object\n",
            " 9   Sexe                1219999 non-null  object\n",
            " 10  Prenom_Phase_scl_H  1219999 non-null  object\n",
            " 11  Prenom_Phase_scl_F  1219999 non-null  object\n",
            " 12  Prenom_Phase_cl_H   1219999 non-null  object\n",
            " 13  Prenom_Phase_cl_F   1219999 non-null  object\n",
            " 14  Age_H               1219999 non-null  object\n",
            " 15  Age_F               1219999 non-null  object\n",
            " 16  Affinite_1          1219999 non-null  object\n",
            " 17  Affinite_2          1219999 non-null  object\n",
            " 18  Prenom_effectif     1219999 non-null  object\n",
            " 19  Potentiel_prenom    1219999 non-null  object\n",
            " 20  Onoma-Phase_Scl     1219999 non-null  object\n",
            " 21  Onoma-Phase_CL      1219999 non-null  object\n",
            " 22  Top_mon             127115 non-null   object\n",
            "dtypes: object(23)\n",
            "memory usage: 214.1+ MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "239a362c"
      },
      "source": [
        "#nombre de modalit√©s de chaque variables (dans un dataframe)\n",
        "def nombre_mod(data2):\n",
        "    #cr√©ation d'un dataframe vide\n",
        "    dff= pd.DataFrame(columns=[\"VARIABLE\",\"NOMBRE_MOD\", \"NOMBRE_MOD_SANS_NA\"])\n",
        "    for i in range(data2.shape[1]): # sans compter les valeurs manquantes\n",
        "        taille =len(data2.iloc[:,i].value_counts(dropna=False))\n",
        "        taille_1 = len(data2.iloc[:,i].value_counts(dropna=True) )\n",
        "        dff=dff.append({\"VARIABLE\": colonnes[i],\"NOMBRE_MOD\":taille, \"NOMBRE_MOD_SANS_NA\":taille_1 }, ignore_index=True)\n",
        "    return dff\n",
        "\n",
        "# s√©lection des corr√©lations les plus importantes\n",
        "def variables_corr(tableau_corr, seuil):\n",
        "    colonnes = tableau_corr.columns\n",
        "    val_temp = 0 \n",
        "    variables_corr_pos=[] ; variables_corr_pos_val=[]\n",
        "    variables_corr_neg=[] ; variables_corr_neg_val=[]\n",
        "    for i in range(tableau_corr.shape[0]):  \n",
        "        for j in range(tableau_corr.shape[0]):\n",
        "            if i<j: #i!=j:\n",
        "                if (tableau_corr.iloc[i,j] > seuil):\n",
        "                    variables_corr_pos.append(colonnes[j])\n",
        "                    variables_corr_pos_val.append(round( tableau_corr.iloc[i,j], 2))\n",
        "                    val_temp += 1\n",
        "\n",
        "                if (tableau_corr.iloc[i,j] <-seuil):\n",
        "                    variables_corr_neg.append(colonnes[j])\n",
        "                    variables_corr_neg_val.append(round( tableau_corr.iloc[i,j], 2))\n",
        "                    val_temp += 1\n",
        "\n",
        "        if (len(variables_corr_pos) > 0) | (len(variables_corr_neg) >0) :\n",
        "            print(\"variable : \", colonnes[i])\n",
        "            if len(variables_corr_pos) > 0:    \n",
        "                print(\"corr pos\", variables_corr_pos)\n",
        "                print(\"corr pos\", variables_corr_pos_val)\n",
        "                val_temp += 1\n",
        "\n",
        "            if len(variables_corr_neg) >0:  \n",
        "                print(\"corr neg\", variables_corr_neg)\n",
        "                print(\"corr neg\", variables_corr_neg_val)\n",
        "                val_temp += 1\n",
        "            print(\"\")\n",
        "        variables_corr_pos = variables_corr_pos*0\n",
        "        variables_corr_neg = variables_corr_pos*0\n",
        "\n",
        "        variables_corr_pos_val = variables_corr_pos_val*0\n",
        "        variables_corr_neg_val = variables_corr_pos_val*0\n",
        "    if val_temp == 0:\n",
        "        print(\"IL N'Y A PAS DE CORRELATION ENTRE LES VARIABLES PAR RAPPORT AU SEUIL PRIS\")\n",
        "        \n",
        "\n",
        "def evaluation(model, X_train, y_train, X_test, y_test, scoring, plot):\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    print(\"test set : \")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(classification_report(y_test, y_pred)) \n",
        "    print(\"train set : \")\n",
        "    print(confusion_matrix(y_train, model.predict(X_train)))  \n",
        "    print(classification_report(y_train, model.predict(X_train) ))\n",
        "\n",
        "    if plot == True:\n",
        "        N, train_score, val_score = learning_curve(model, X_train, y_train, shuffle=True, cv = 4, scoring = scoring, train_sizes = np.linspace(0.1, 1, 6) )\n",
        "\n",
        "        plt.figure(figsize = (10,6))\n",
        "        plt.plot(N, train_score.mean(axis=1), label =\"train_score\")\n",
        "        plt.plot(N, val_score.mean(axis=1), label =\"cross_validation_score\")\n",
        "        plt.legend()\n",
        "    else :\n",
        "        print(\"GRAPHIQUE NON DEMANDE\")\n",
        "\n",
        "# Comme il n'y a pas de valeurs manquantes (√† la place il y a un nombre), le seul traitement qu'on fait c'est tranformer\n",
        "# le type de variable (les variables continues deviennent qualitatives)\n",
        "def data_processing(df):\n",
        "    \"\"\" \n",
        "    for i in range(0,len(df.columns)):    \n",
        "        df[df.columns[i]].fillna(100.0, inplace=True) #On remplace les donn√©es manquantes par 100\n",
        "    for i in range(0,len(df.columns)):\n",
        "        print(df[df.columns[i]].value_counts(dropna=False))    \n",
        "    \"\"\"\n",
        "    \n",
        "   #Transformation de toutes les variables en facteurs         \n",
        "    for i in range(0,len(df.columns)):\n",
        "        df[df.columns[i]] = df[df.columns[i]].astype('category')\n",
        "    return df.to_numpy() #.as_matrix()\n",
        "\n",
        "\n",
        "def quarantiles(model, data_orig, affichage, save, path):\n",
        "    # position de la derni√®re variable explicative dans le dataset\n",
        "    nb_var = data_orig.shape[1]-1\n",
        "\n",
        "    # predict sur tous les individus (avec et sans classe IFI+)\n",
        "    tous_probas = model.predict_proba(data_orig.iloc[:,1:nb_var])\n",
        "    df_tous = pd.DataFrame({'IDENT': data_orig.iloc[:,0] , 'PROBA': tous_probas[:,0] })\n",
        "    #df_tous\n",
        "    \n",
        "    # valeurs ordonn√©es pour diviser apr√®s\n",
        "    df_tous=df_tous.sort_values(by='PROBA', ascending=True)\n",
        "    #df_tous\n",
        "    print(df_tous)\n",
        "    \n",
        "    #v√©rification\n",
        "    print(df_tous['PROBA'].value_counts())\n",
        "\n",
        "    # quarantiles\n",
        "    df_temp =pd.DataFrame( pd.qcut(df_tous['PROBA'],q= 20)  )\n",
        "    print(df_temp)\n",
        "\n",
        "    # ajout par index (IMPORTANTE)\n",
        "    df_tous[\"TRANCHES\"]=pd.DataFrame(df_temp.iloc[:,0].to_numpy(),index= df_temp.index)\n",
        "    #print(df_tous)\n",
        "    \n",
        "    # pour la colonne IFI+ :\n",
        "    # remplissage de la derni√®re colonne par 2 (VALABLE QUE POUR CE DATA, MODIFIER POUR D'AUTRES)\n",
        "    data_temp_t = data_orig.copy()\n",
        "    # remplacement\n",
        "    data_temp_t[\"Top_mon\"] =  data_temp_t[\"Top_mon\"].replace(1.0,'1')\n",
        "    data_temp_t[\"Top_mon\"] =  data_temp_t[\"Top_mon\"].replace(2.0,'2')\n",
        "    data_all_complet_class = data_temp_t.fillna('2')\n",
        "    #data_all_complet_class\n",
        "\n",
        "    # jointure\n",
        "    ident_class_tous = data_all_complet_class[[\"IDENT\",\"Top_mon\"]]\n",
        "    tableau_resultats = pd.merge(df_tous,ident_class_tous)\n",
        "    #tableau_resultats\n",
        "\n",
        "    # tranches finales\n",
        "    tab_cross_temp = pd.crosstab(tableau_resultats[\"TRANCHES\"],tableau_resultats[\"Top_mon\"])\n",
        "    #print(tab_cross_temp); print(\"-----------------------\")\n",
        "\n",
        "    # cr√©ation d'une colonne total\n",
        "    tab_cross_temp[\"TOTAL\"]=tab_cross_temp[\"1\"]+tab_cross_temp[\"2\"]\n",
        "    \n",
        "    # affichage\n",
        "    if affichage ==True:        \n",
        "        print(tab_cross_temp)\n",
        "    \n",
        "    # cr√©ation du tableau final en √©liminant la colonne 2\n",
        "    tab_pour_excel = tab_cross_temp.drop([\"2\"], axis=1)\n",
        "    \n",
        "    # enregistrement sous Excel\n",
        "    if save == True:\n",
        "        tab_pour_excel.to_excel(path)\n",
        "\n",
        "\n",
        "# √©limination des variables trop corr√©l√©es (choix manuel)\n",
        "def elimination_val_corr(data):\n",
        "    data = data.drop(columns=[\"\"])\n",
        "    return data\n",
        "          \n",
        "\n",
        "\n",
        "\n"
      ],
      "id": "239a362c",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cfbe9f8"
      },
      "source": [
        ""
      ],
      "id": "1cfbe9f8",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e46a9d46"
      },
      "source": [
        "##############################################################################################################\n",
        "#                                                   PREMIERS TESTS\n",
        "##############################################################################################################\n"
      ],
      "id": "e46a9d46",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "367ea9ec"
      },
      "source": [
        "#################################################################################################\n",
        "#                       SANS VARIABLES CORR ET ENCODAGE DUMMIES\n",
        "#################################################################################################\n"
      ],
      "id": "367ea9ec",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eea29b1"
      },
      "source": [
        "# test predict individus sans classe\n",
        "data = data_orig.copy()\n",
        "\n",
        "# on √©limine les variables dons\n",
        "data=data.drop([\"GeoFaz_cl\", \"ImmoFaz_Scl\", \"ImmoFaz_cl\", \"Prenom_Phase_cl_H\", \"Prenom_Phase_cl_F\",\n",
        "                \"Onoma-Phase_Scl\", \"Onoma-Phase_CL\"],axis=1)\n",
        "\n",
        "# encodage Onehot sur toutes les donn√©es (on √©vite ainsi les erreurs futures)\n",
        "nb_var = data.shape[1] - 1\n",
        "data_1_22 = pd.get_dummies(data.iloc[:,1:(data.shape[1]-1)], columns=data.columns[1:(data.shape[1]-1)] )\n",
        "data_var_qualitatives_temp =  pd.concat([data[\"IDENT\"], data_1_22, data[\"Top_mon\"]], axis=1)\n",
        "data = data_var_qualitatives_temp\n",
        "#encodage = OneHotEncoder()\n",
        "#encodage.fit(data_processing(data.iloc[:,1:nb_var]))\n",
        "\n",
        "# √©limination des individus n'ayant pas de valeur pour la varialbe IFI+\n",
        "\"\"\"IMPORTANT\"\"\"\n",
        "data_sans_nan = data[(data.isnull()).sum(axis=1) == 0]\n",
        "\n",
        "#conversion du type de variable\n",
        "for i in range(1,data_sans_nan.shape[1]):\n",
        "    data_sans_nan.iloc[:,i]=data_sans_nan.iloc[:,i].astype(int)\n",
        "\n",
        "# base de donn√©es avec des variables corr√©l√©es et avec encodage OneHot\n",
        "data =data_sans_nan\n",
        "\n",
        "nb_var = data.shape[1] - 1\n",
        "train_set, test_set = train_test_split(data, test_size = 0.2, random_state=0 )\n",
        "\n",
        "train_X_s = (train_set.iloc[:,1:nb_var]).to_numpy()\n",
        "train_Y_s = np.asanyarray(train_set.iloc[:,nb_var])\n",
        "\n",
        "test_X_s = (test_set.iloc[:,1:nb_var]).to_numpy()\n",
        "test_Y_s = np.asanyarray(test_set.iloc[:,nb_var])\n"
      ],
      "id": "4eea29b1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bfe404f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52bfbf30-c52d-4d58-f552-1cbbd943e5c8"
      },
      "source": [
        "model_reg_logistic = LogisticRegression(random_state =0, max_iter= 10000, class_weight=\"balanced\" )\n",
        "\n",
        "param = {'C':[0.01,0.05,0.1,1,2], 'solver': ['liblinear','newton-cg', 'lbfgs'], 'penalty': [\"l1\",\"l2\",\"none\"] } \n",
        "\n",
        "grid_reg_logistic = GridSearchCV(model_reg_logistic, param_grid = param, cv=5, scoring ='recall', n_jobs=2 )\n",
        "resultat_reg_logistic = grid_reg_logistic.fit(train_X_s, train_Y_s)\n",
        "print(resultat_reg_logistic.best_params_)\n"
      ],
      "id": "1bfe404f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4883d96d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ec217d1-32f7-4214-eb51-89634d1f38f7"
      },
      "source": [
        "#model_17_cw = LogisticRegression(random_state =0,solver=\"lbfgs\",penalty=\"none\" ,max_iter= 10000, class_weight=\"balanced\")\n",
        "model_17_cw = LogisticRegression(random_state =0, C=0.01,penalty=\"l2\" , solver=\"newton-cg\", max_iter= 10000, class_weight=\"balanced\")\n",
        "\n",
        "evaluation(model_17_cw, train_X_s, train_Y_s, test_X_s, test_Y_s, scoring=\"recall\", plot=False )"
      ],
      "id": "4883d96d",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test set : \n",
            "[[ 2545  2134]\n",
            " [ 7548 13196]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.25      0.54      0.34      4679\n",
            "           2       0.86      0.64      0.73     20744\n",
            "\n",
            "    accuracy                           0.62     25423\n",
            "   macro avg       0.56      0.59      0.54     25423\n",
            "weighted avg       0.75      0.62      0.66     25423\n",
            "\n",
            "train set : \n",
            "[[10420  8357]\n",
            " [29252 53663]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.26      0.55      0.36     18777\n",
            "           2       0.87      0.65      0.74     82915\n",
            "\n",
            "    accuracy                           0.63    101692\n",
            "   macro avg       0.56      0.60      0.55    101692\n",
            "weighted avg       0.75      0.63      0.67    101692\n",
            "\n",
            "GRAPHIQUE NON DEMANDE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05a41696",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1553242f-8667-4538-8b66-b3002ccdec45"
      },
      "source": [
        "#data_var_qualitatives_temp\n",
        "quarantiles(model=model_17_cw, data_orig= data, affichage=True,\n",
        "            save=False, path = \"C:/Users/Christian/Desktop/sans_dons_encodage_dummies_logistic_regression.xlsx\")"
      ],
      "id": "05a41696",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                     IDENT     PROBA\n",
            "22780   000227810010281361  0.188762\n",
            "114600  001146010010525575  0.201295\n",
            "112625  001126260010522654  0.203130\n",
            "87933   000879340010401859  0.206902\n",
            "87934   000879350010401859  0.206902\n",
            "...                    ...       ...\n",
            "77961   000779620010392936  0.916953\n",
            "107367  001073680010503920  0.922584\n",
            "99430   000994310010412631  0.926244\n",
            "107473  001074740010504178  0.926244\n",
            "106585  001065860010500476  0.926244\n",
            "\n",
            "[127115 rows x 2 columns]\n",
            "0.913447    50\n",
            "0.654803    33\n",
            "0.750406    33\n",
            "0.733709    26\n",
            "0.738316    23\n",
            "            ..\n",
            "0.734021     1\n",
            "0.506568     1\n",
            "0.556617     1\n",
            "0.586337     1\n",
            "0.337920     1\n",
            "Name: PROBA, Length: 96552, dtype: int64\n",
            "                 PROBA\n",
            "22780   (0.188, 0.319]\n",
            "114600  (0.188, 0.319]\n",
            "112625  (0.188, 0.319]\n",
            "87933   (0.188, 0.319]\n",
            "87934   (0.188, 0.319]\n",
            "...                ...\n",
            "77961   (0.699, 0.926]\n",
            "107367  (0.699, 0.926]\n",
            "99430   (0.699, 0.926]\n",
            "107473  (0.699, 0.926]\n",
            "106585  (0.699, 0.926]\n",
            "\n",
            "[127115 rows x 1 columns]\n",
            "Top_mon            1     2  TOTAL\n",
            "TRANCHES                         \n",
            "(0.188, 0.319]   535  5821   6356\n",
            "(0.319, 0.345]   637  5719   6356\n",
            "(0.345, 0.364]   687  5669   6356\n",
            "(0.364, 0.382]   766  5590   6356\n",
            "(0.382, 0.399]   799  5556   6355\n",
            "(0.399, 0.414]   869  5487   6356\n",
            "(0.414, 0.428]   850  5505   6355\n",
            "(0.428, 0.442]   968  5388   6356\n",
            "(0.442, 0.456]   971  5385   6356\n",
            "(0.456, 0.47]   1072  5284   6356\n",
            "(0.47, 0.483]   1009  5346   6355\n",
            "(0.483, 0.498]  1152  5205   6357\n",
            "(0.498, 0.512]  1183  5173   6356\n",
            "(0.512, 0.528]  1228  5126   6354\n",
            "(0.528, 0.546]  1320  5036   6356\n",
            "(0.546, 0.566]  1386  4970   6356\n",
            "(0.566, 0.594]  1496  4859   6355\n",
            "(0.594, 0.634]  1639  4718   6357\n",
            "(0.634, 0.699]  2037  4319   6356\n",
            "(0.699, 0.926]  2852  3503   6355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08RvvFVaIldS"
      },
      "source": [
        ""
      ],
      "id": "08RvvFVaIldS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a62db87"
      },
      "source": [
        "####################################################################################\n",
        "#                                FIN PREMIERS TESTS\n",
        "####################################################################################"
      ],
      "id": "6a62db87",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "178704f4"
      },
      "source": [
        ""
      ],
      "id": "178704f4",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2b90ca16"
      },
      "source": [
        ""
      ],
      "id": "2b90ca16",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1d2bc66a"
      },
      "source": [
        ""
      ],
      "id": "1d2bc66a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e52f95fe"
      },
      "source": [
        ""
      ],
      "id": "e52f95fe",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5d4494ad"
      },
      "source": [
        "####################################################################################################\n",
        "#\n",
        "#                                        DATA AUGMENTATION\n",
        "#\n",
        "####################################################################################################"
      ],
      "id": "5d4494ad",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8f4843be"
      },
      "source": [
        "####################################################################################################\n",
        "#\n",
        "#                                       UNDER-SAMPLING  ET OVER-SAMPLING\n",
        "#\n",
        "####################################################################################################"
      ],
      "id": "8f4843be",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LK3t4SFt4lB"
      },
      "source": [
        "##########################################\n",
        "# AVEC VARIABLES DONS ET ENCODAGE DUMMIES\n",
        "##########################################\n",
        "\n",
        "# test predict individus sans classe\n",
        "data = data_orig.copy()\n",
        "\n",
        "# on √©limine les variables dons\n",
        "data=data.drop([\"GeoFaz_cl\", \"ImmoFaz_Scl\", \"ImmoFaz_cl\", \"Prenom_Phase_cl_H\", \"Prenom_Phase_cl_F\",\n",
        "                \"Onoma-Phase_Scl\", \"Onoma-Phase_CL\"],axis=1)\n",
        "\n",
        "# encodage Onehot sur toutes les donn√©es (on √©vite ainsi les erreurs futures)\n",
        "nb_var = data.shape[1] - 1\n",
        "data_1_22 = pd.get_dummies(data.iloc[:,1:(data.shape[1]-1)], columns=data.columns[1:(data.shape[1]-1)] )\n",
        "data_var_qualitatives_temp =  pd.concat([data[\"IDENT\"], data_1_22, data[\"Top_mon\"]], axis=1)\n",
        "data = data_var_qualitatives_temp\n",
        "#encodage = OneHotEncoder()\n",
        "#encodage.fit(data_processing(data.iloc[:,1:nb_var]))\n",
        "\n",
        "# √©limination des individus n'ayant pas de valeur pour la varialbe IFI+\n",
        "\"\"\"IMPORTANT\"\"\"\n",
        "data_sans_nan = data[(data.isnull()).sum(axis=1) == 0]\n",
        "\n",
        "#conversion du type de variable\n",
        "for i in range(1,data_sans_nan.shape[1]):\n",
        "    data_sans_nan.iloc[:,i]=data_sans_nan.iloc[:,i].astype(int)\n",
        "\n",
        "# base de donn√©es avec des variables corr√©l√©es et avec encodage OneHot\n",
        "data =data_sans_nan\n",
        "\n",
        "nb_var = data.shape[1] - 1\n",
        "train_set, test_set = train_test_split(data, test_size = 0.2, random_state=0 )\n",
        "\n",
        "train_X_s = (train_set.iloc[:,1:nb_var]).to_numpy()\n",
        "train_Y_s = np.asanyarray(train_set.iloc[:,nb_var])\n",
        "\n",
        "test_X_s = (test_set.iloc[:,1:nb_var]).to_numpy()\n",
        "test_Y_s = np.asanyarray(test_set.iloc[:,nb_var])\n"
      ],
      "id": "_LK3t4SFt4lB",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bK9oJU4tzzh"
      },
      "source": [
        "\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "id": "6bK9oJU4tzzh",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sa_nSucG6qO-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6799c4b6-471d-4b8a-a9e0-d8d6b3285685"
      },
      "source": [
        "\"\"\"\n",
        "# dimension du train set\n",
        "print(\"Sans aucun traitement sur le train set : \" , np.unique(train_Y_s, return_counts=True))\n",
        "\n",
        "# diminution des donn√©es\n",
        "t2 = TomekLinks()\n",
        "X_resampled, y_resampled = t2.fit_resample(train_X_s[:,:nb_var] , train_Y_s )\n",
        "print(\"Apr√®s under-sampling : \", np.unique(y_resampled, return_counts=True ))\n",
        "\n",
        "# augmentation des donn√©es\n",
        "tl = SMOTE()\n",
        "X_resampled, y_resampled = tl.fit_resample(X_resampled, y_resampled )\n",
        "print(\"Apr√®s over-smapling : \" , np.unique(y_resampled, return_counts=True ))\n",
        "\n",
        "\n",
        "# enregistrement du nouveau train set car le traitement du under-sampling prendre du temps \n",
        "pd.DataFrame(np.concatenate((X_resampled, y_resampled.reshape((y_resampled.shape[0],1)) ),\n",
        "                            axis=1)).to_csv(\"/content/drive/MyDrive/spad_score_method_1/spad_projection_FDFTOT21/sans_val_corr_spad_under_over_sampling.txt\",\n",
        "                                            sep=\" \", index =False , header = False, encoding =\"utf-8\")\n",
        "\n",
        "\"\"\""
      ],
      "id": "sa_nSucG6qO-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sans aucun traitement sur le train set :  (array([1, 2]), array([18777, 82915]))\n",
            "Apr√®s under-sampling :  (array([1, 2]), array([18777, 80013]))\n",
            "Apr√®s over-smapling :  (array([1, 2]), array([80013, 80013]))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mp7wBBvMtWz"
      },
      "source": [
        ""
      ],
      "id": "5mp7wBBvMtWz",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yk6snWL1MyHc"
      },
      "source": [
        "# R√©sultat du traitement sur le train set (under-sampling et over-sampling)\n",
        "abc_test = pd.read_csv(\"/content/drive/MyDrive/spad_score_method_1/spad_projection_FDFTOT21/sans_val_corr_spad_under_over_sampling.txt\", delim_whitespace=\"\\t\", header = None, low_memory=False, dtype=\"Int64\" ) #, dtype='Int64')\n",
        "abc_np = abc_test.to_numpy(dtype=\"Int64\")\n",
        "\n",
        "X_resampled = abc_np[:,:-1]\n",
        "y_resampled = abc_np[:, abc_np.shape[1] -1 ]\n"
      ],
      "id": "yk6snWL1MyHc",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5C3X2ODQxNu",
        "outputId": "dfcccd87-6bff-45b3-e4b4-83a017049aa6"
      },
      "source": [
        "X_resampled.shape, y_resampled.shape"
      ],
      "id": "X5C3X2ODQxNu",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((160026, 269), (160026,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMpSRRr4WTrV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb4abeae-9f63-4669-87d0-4bf975b2d674"
      },
      "source": [
        "model_reg_logistic = LogisticRegression(random_state =0, max_iter= 10000, class_weight=\"balanced\" )\n",
        "\n",
        "param = {'C':[0.01,0.1,1], 'solver': ['liblinear','newton-cg', 'lbfgs'], 'penalty': [\"l1\",\"l2\",\"none\"] } \n",
        "\n",
        "grid_reg_logistic = GridSearchCV(model_reg_logistic, param_grid = param, cv=5, scoring ='recall', n_jobs=2 )\n",
        "resultat_reg_logistic = grid_reg_logistic.fit(train_X_s, train_Y_s)\n",
        "print(resultat_reg_logistic.best_params_)"
      ],
      "id": "dMpSRRr4WTrV",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'C': 0.01, 'penalty': 'l2', 'solver': 'newton-cg'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rwIUJx67WTuF",
        "outputId": "b8776c7a-74fc-48d6-bf47-cfcf2d3063d0"
      },
      "source": [
        "model_17_cw = LogisticRegression(random_state =0,C=0.01, penalty=\"l2\", solver=\"newton-cg\", max_iter= 10000, class_weight=\"balanced\")\n",
        "\n",
        "evaluation(model_17_cw, X_resampled, y_resampled, test_X_s, test_Y_s, scoring=\"recall\", plot=False )"
      ],
      "id": "rwIUJx67WTuF",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test set : \n",
            "[[  608  4071]\n",
            " [  798 19946]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.43      0.13      0.20      4679\n",
            "           2       0.83      0.96      0.89     20744\n",
            "\n",
            "    accuracy                           0.81     25423\n",
            "   macro avg       0.63      0.55      0.55     25423\n",
            "weighted avg       0.76      0.81      0.76     25423\n",
            "\n",
            "train set : \n",
            "[[61874 18139]\n",
            " [ 2978 77035]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.95      0.77      0.85     80013\n",
            "           2       0.81      0.96      0.88     80013\n",
            "\n",
            "    accuracy                           0.87    160026\n",
            "   macro avg       0.88      0.87      0.87    160026\n",
            "weighted avg       0.88      0.87      0.87    160026\n",
            "\n",
            "GRAPHIQUE NON DEMANDE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vy-NGURDWT0I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c76ca839-4af1-4003-b0c6-a9e48eb3e467"
      },
      "source": [
        "model_17_cw = LogisticRegression(random_state =0,C=1, penalty=\"l2\", solver=\"newton-cg\", max_iter= 100)\n",
        "\n",
        "evaluation(model_17_cw, X_resampled, y_resampled, test_X_s, test_Y_s, scoring=\"recall\", plot=False )"
      ],
      "id": "vy-NGURDWT0I",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "test set : \n",
            "[[  397  4282]\n",
            " [  451 20293]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.47      0.08      0.14      4679\n",
            "           2       0.83      0.98      0.90     20744\n",
            "\n",
            "    accuracy                           0.81     25423\n",
            "   macro avg       0.65      0.53      0.52     25423\n",
            "weighted avg       0.76      0.81      0.76     25423\n",
            "\n",
            "train set : \n",
            "[[61120 18893]\n",
            " [ 1628 78385]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.97      0.76      0.86     80013\n",
            "           2       0.81      0.98      0.88     80013\n",
            "\n",
            "    accuracy                           0.87    160026\n",
            "   macro avg       0.89      0.87      0.87    160026\n",
            "weighted avg       0.89      0.87      0.87    160026\n",
            "\n",
            "GRAPHIQUE NON DEMANDE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WzdLmFXvbcCq"
      },
      "source": [
        ""
      ],
      "id": "WzdLmFXvbcCq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6275209a"
      },
      "source": [
        "#####################################################################################\n",
        "###################################################################################\n",
        "####################################################################################\n",
        "####################################################################################"
      ],
      "id": "6275209a",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6af0b20"
      },
      "source": [
        ""
      ],
      "id": "b6af0b20",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2744b893"
      },
      "source": [
        ""
      ],
      "id": "2744b893",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76389aea"
      },
      "source": [
        "data_1 = data_non_corr[data_non_corr[\"IFI+\"]==1]\n",
        "data_2 = data_non_corr[data_non_corr[\"IFI+\"]==2]"
      ],
      "id": "76389aea",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "12705dfd"
      },
      "source": [
        "\n"
      ],
      "id": "12705dfd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "589cc202"
      },
      "source": [
        "\n",
        "probas = model_17.predict_proba( data_non_corr.iloc[:,1:nb_var] ) # *1000 data_1\n",
        "#Cr√©ation des quarantiles\n",
        "d = {'id': data_non_corr.iloc[:,0] , 'proba': probas[:,0]} # data_1\n",
        "df = pd.DataFrame(data=d)\n",
        "df.to_excel(\"C:/Users/Christian/Desktop/test_test.xlsx\") \n",
        "\n"
      ],
      "id": "589cc202",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7a4e111d"
      },
      "source": [
        "df"
      ],
      "id": "7a4e111d",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a274eeb3"
      },
      "source": [
        "somme_quarantiles = pd.DataFrame(data =\"-\", index=[\"somme\"], columns = [\"Tranches de Score\",\"Zone\",\"Eff.\", \"Pourc.\", \"Pourc. cumul√©\"] )\n"
      ],
      "id": "a274eeb3",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02569934"
      },
      "source": [
        "info_quarantiles = pd.DataFrame(data =\"-\", index=range(40), columns = [\"Tranches de Score\",\"Zone\",\"Eff.\", \"Pourc.\", \"Pourc. cumul√©\"] )\n"
      ],
      "id": "02569934",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3910c876"
      },
      "source": [
        "# prendre uniquement les probalit√©s sup√©rieurs √† 50\n",
        "\n",
        "def remplissage_score_1(probas, taux):\n",
        "\n",
        "    somme_quarantiles = pd.DataFrame(data =\"\", index=[\"somme\"], columns = [\"Tranches de Score\",\"Zone\",\"Eff.\", \"Pourc.\", \"Pourc. cumul√©\"] )\n",
        "    info_quarantiles = pd.DataFrame(data =\"\", index=range(40), columns = [\"Tranches de Score\",\"Zone\",\"Eff.\", \"Pourc.\", \"Pourc. cumul√©\"] )\n",
        "\n",
        "    num = 0\n",
        "    somme_cum = 0\n",
        "    dim_qua = info_quarantiles.shape[0]\n",
        "    val_max = max(probas[:,0])\n",
        "    val_inter = val_max/40\n",
        "    val_change = 0\n",
        "\n",
        "    for k in range(dim_qua) :   \n",
        "        if k == (dim_qua-1) : \n",
        "            somme = ((val_change <=probas[:,0]) & (probas[:,0]<= val_change + val_inter)).sum()\n",
        "        else :\n",
        "            somme = ((val_change <=probas[:,0]) & (probas[:,0]< val_change + val_inter)).sum()\n",
        "            \n",
        "        if k < (dim_qua/2 - (4+1)) : \n",
        "            info_quarantiles.iloc[k,1] = 'R'\n",
        "        elif k > (dim_qua/2 -(1) ) :\n",
        "            info_quarantiles.iloc[k,1] = 'V'\n",
        "        else:\n",
        "            info_quarantiles.iloc[k,1] = '-'\n",
        "            \n",
        "        if k == 0:\n",
        "            info_quarantiles.iloc[k,0] = str(num)+\" - \"+str(num+25)\n",
        "        else :\n",
        "            info_quarantiles.iloc[k,0] = str(num+1)+\" - \"+str(num+25)\n",
        "        \n",
        "        info_quarantiles.iloc[k,2] = somme\n",
        "        info_quarantiles.iloc[k,3] = round(somme/probas.shape[0],2)\n",
        "\n",
        "        somme_cum = somme_cum + info_quarantiles.iloc[k,3]\n",
        "\n",
        "        info_quarantiles.iloc[k,4] = somme_cum\n",
        "        num = num + 25\n",
        "        val_change = val_change + val_inter\n",
        "\n",
        "    somme_quarantiles.iloc[0,0] = \"Ensemble\"    \n",
        "    somme_quarantiles.iloc[0,2] = info_quarantiles.iloc[:,2].sum()\n",
        "    somme_quarantiles.iloc[0,3] = info_quarantiles.iloc[:,3].sum()\n",
        "    somme_quarantiles.iloc[0,4] = info_quarantiles.iloc[39,4]\n",
        "\n",
        "    return info_quarantiles.append(somme_quarantiles)\n",
        "\n",
        "    \n",
        "    "
      ],
      "id": "3910c876",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e829e456"
      },
      "source": [
        "remplissage_score_1(probas, taux=4)\n"
      ],
      "id": "e829e456",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcc4fc11"
      },
      "source": [
        ""
      ],
      "id": "dcc4fc11",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85f33c1b"
      },
      "source": [
        "  "
      ],
      "id": "85f33c1b",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fb7f3dd"
      },
      "source": [
        ""
      ],
      "id": "8fb7f3dd",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8cabf642"
      },
      "source": [
        "#####################################################################################\n",
        "####################################################################################"
      ],
      "id": "8cabf642",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7572e75"
      },
      "source": [
        "#from scipy.stats import kstest\n",
        "#test_stat = kstest(x, 'norm')"
      ],
      "id": "c7572e75",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eff029de"
      },
      "source": [
        ""
      ],
      "id": "eff029de",
      "execution_count": null,
      "outputs": []
    }
  ]
}