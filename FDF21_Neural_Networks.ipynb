{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FDF21_Neural_Networks.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMQibqrhWXcANZvilvLP2DV"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FL4NG4bKoPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b76399f0-e498-49d2-b784-0894d7a02949"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmD80CCCK5ga"
      },
      "source": [
        "# option d'affichage des résultats\n",
        "pd.set_option(\"display.max_row\",130)\n",
        "pd.set_option(\"display.max_columns\",100)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkc12UYCK5ie"
      },
      "source": [
        "# les noms des variables\n",
        "\n",
        "colonnes =([\"IDENT\", \"TypeHabi\", \"GeoFaz_Scl\", \"GeoFaz_cl\", \"ImmoFaz_Scl\", \"ImmoFaz_cl\", \"Anciennete\",\n",
        "            \"Logement_prix_m2\", \"Mediane_RFR\", \"Sexe\", \"Prenom_Phase_scl_H\", \"Prenom_Phase_scl_F\",\n",
        "            \"Prenom_Phase_cl_H\", \"Prenom_Phase_cl_F\", \"Age_H\", \"Age_F\", \"Affinite_1\", \"Affinite_2\",\n",
        "            \"Prenom_effectif\", \"Potentiel_prenom\", \"Onoma-Phase_Scl\", \"Onoma-Phase_CL\", \"Top_mon\"])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqjK-LTnK5k3"
      },
      "source": [
        "# importation du fichier (changer le chemin d'accès)\n",
        "''' Faites attention au type de fichier, au délimiteur des valeurs (ça doit être unique et non multiple),\n",
        "au header et à la lecture des types d'objets (low_memory) '''\n",
        "\n",
        "data_orig = pd.read_csv(\"/content/drive/MyDrive/spad_score_method_1/spad_projection_FDFTOT21/my_data_FDFTOT21.txt\", delim_whitespace=\"\\t\", header = None, names=colonnes, low_memory=False, )#, dtype='Int64')\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Snpt62qBK5nN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c83094b0-73f5-45a1-e588-9e3df546d689"
      },
      "source": [
        "''' copie superficielle (peu profonde) du dataset original pour ne pas modifier les valeurs\n",
        "d'origine par erreur plus tard \n",
        "'''\n",
        "data = data_orig.copy()\n",
        "data.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1219999, 23)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vbTTDlg_LGIt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "outputId": "0273896e-1f9e-4baf-9e8f-501802dc06cb"
      },
      "source": [
        "# visualisation des premiers lignes\n",
        "data.head()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>IDENT</th>\n",
              "      <th>TypeHabi</th>\n",
              "      <th>GeoFaz_Scl</th>\n",
              "      <th>GeoFaz_cl</th>\n",
              "      <th>ImmoFaz_Scl</th>\n",
              "      <th>ImmoFaz_cl</th>\n",
              "      <th>Anciennete</th>\n",
              "      <th>Logement_prix_m2</th>\n",
              "      <th>Mediane_RFR</th>\n",
              "      <th>Sexe</th>\n",
              "      <th>Prenom_Phase_scl_H</th>\n",
              "      <th>Prenom_Phase_scl_F</th>\n",
              "      <th>Prenom_Phase_cl_H</th>\n",
              "      <th>Prenom_Phase_cl_F</th>\n",
              "      <th>Age_H</th>\n",
              "      <th>Age_F</th>\n",
              "      <th>Affinite_1</th>\n",
              "      <th>Affinite_2</th>\n",
              "      <th>Prenom_effectif</th>\n",
              "      <th>Potentiel_prenom</th>\n",
              "      <th>Onoma-Phase_Scl</th>\n",
              "      <th>Onoma-Phase_CL</th>\n",
              "      <th>Top_mon</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10010000001</td>\n",
              "      <td>2</td>\n",
              "      <td>81</td>\n",
              "      <td>8</td>\n",
              "      <td>91</td>\n",
              "      <td>9</td>\n",
              "      <td>6</td>\n",
              "      <td>21</td>\n",
              "      <td>21</td>\n",
              "      <td>1</td>\n",
              "      <td>71</td>\n",
              "      <td>41</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>51</td>\n",
              "      <td>5</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20010000006</td>\n",
              "      <td>1</td>\n",
              "      <td>75</td>\n",
              "      <td>7</td>\n",
              "      <td>43</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>2</td>\n",
              "      <td>71</td>\n",
              "      <td>64</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>12</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>4</td>\n",
              "      <td>13</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>30010000011</td>\n",
              "      <td>1</td>\n",
              "      <td>76</td>\n",
              "      <td>7</td>\n",
              "      <td>43</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>16</td>\n",
              "      <td>3</td>\n",
              "      <td>54</td>\n",
              "      <td>81</td>\n",
              "      <td>5</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>4</td>\n",
              "      <td>18</td>\n",
              "      <td>36</td>\n",
              "      <td>3</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>40010000013</td>\n",
              "      <td>3</td>\n",
              "      <td>75</td>\n",
              "      <td>7</td>\n",
              "      <td>43</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>1</td>\n",
              "      <td>71</td>\n",
              "      <td>36</td>\n",
              "      <td>7</td>\n",
              "      <td>3</td>\n",
              "      <td>12</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>19</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>21</td>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>50010000015</td>\n",
              "      <td>2</td>\n",
              "      <td>33</td>\n",
              "      <td>3</td>\n",
              "      <td>44</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>7</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>71</td>\n",
              "      <td>42</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>5</td>\n",
              "      <td>14</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>2.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         IDENT  TypeHabi  GeoFaz_Scl  GeoFaz_cl  ImmoFaz_Scl  ImmoFaz_cl  \\\n",
              "0  10010000001         2          81          8           91           9   \n",
              "1  20010000006         1          75          7           43           4   \n",
              "2  30010000011         1          76          7           43           4   \n",
              "3  40010000013         3          75          7           43           4   \n",
              "4  50010000015         2          33          3           44           4   \n",
              "\n",
              "   Anciennete  Logement_prix_m2  Mediane_RFR  Sexe  Prenom_Phase_scl_H  \\\n",
              "0           6                21           21     1                  71   \n",
              "1           6                 6           13     2                  71   \n",
              "2           6                 6           16     3                  54   \n",
              "3           4                 6           13     1                  71   \n",
              "4           6                 7           12     1                  71   \n",
              "\n",
              "   Prenom_Phase_scl_F  Prenom_Phase_cl_H  Prenom_Phase_cl_F  Age_H  Age_F  \\\n",
              "0                  41                  7                  4     12      4   \n",
              "1                  64                  7                  6     12      9   \n",
              "2                  81                  5                  8      7     12   \n",
              "3                  36                  7                  3     12     11   \n",
              "4                  42                  7                  4     12      5   \n",
              "\n",
              "   Affinite_1  Affinite_2  Prenom_effectif  Potentiel_prenom  Onoma-Phase_Scl  \\\n",
              "0          20           2                2                 1               51   \n",
              "1           4          12                4                13               12   \n",
              "2           6           6                4                18               36   \n",
              "3          11          19                4                 6               21   \n",
              "4          14           3                3                 1               14   \n",
              "\n",
              "   Onoma-Phase_CL  Top_mon  \n",
              "0               5      1.0  \n",
              "1               1      1.0  \n",
              "2               3      2.0  \n",
              "3               2      1.0  \n",
              "4               1      2.0  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R32oQgCWLGPT"
      },
      "source": [
        "#nombre de modalités de chaque variables (dans un dataframe)\n",
        "def nombre_mod(data2):\n",
        "    #création d'un dataframe vide\n",
        "    dff= pd.DataFrame(columns=[\"VARIABLE\",\"NOMBRE_MOD\", \"NOMBRE_MOD_SANS_NA\"])\n",
        "    for i in range(data2.shape[1]): # sans compter les valeurs manquantes\n",
        "        taille =len(data2.iloc[:,i].value_counts(dropna=False))\n",
        "        taille_1 = len(data2.iloc[:,i].value_counts(dropna=True) )\n",
        "        dff=dff.append({\"VARIABLE\": colonnes[i],\"NOMBRE_MOD\":taille, \"NOMBRE_MOD_SANS_NA\":taille_1 }, ignore_index=True)\n",
        "    return dff\n",
        "\n",
        "# sélection des corrélations les plus importantes\n",
        "def variables_corr(tableau_corr, seuil):\n",
        "    variables_corr_pos=[] ; variables_corr_pos_val=[]\n",
        "    variables_corr_neg=[] ; variables_corr_neg_val=[]\n",
        "    for i in range(tableau_corr.shape[0]):  \n",
        "        for j in range(tableau_corr.shape[0]):\n",
        "            if i<j: #i!=j:\n",
        "                if (tableau_corr.iloc[i,j] > seuil):\n",
        "                    variables_corr_pos.append(colonnes[j+1])\n",
        "                    variables_corr_pos_val.append(round( tableau_corr.iloc[i,j], 2))\n",
        "                if (tableau_corr.iloc[i,j] <-seuil):\n",
        "                    variables_corr_neg.append(colonnes[j+1])\n",
        "                    variables_corr_neg_val.append(round( tableau_corr.iloc[i,j], 2))\n",
        "\n",
        "        if (len(variables_corr_pos) > 0) | (len(variables_corr_neg) >0) :\n",
        "            print(\"variable : \", colonnes[i+1])\n",
        "            if len(variables_corr_pos) > 0:    \n",
        "                print(\"corr pos\", variables_corr_pos)\n",
        "                print(\"corr pos\", variables_corr_pos_val)\n",
        "            if len(variables_corr_neg) >0:  \n",
        "                print(\"corr neg\", variables_corr_neg)\n",
        "                print(\"corr neg\", variables_corr_neg_val)\n",
        "            print(\"\")\n",
        "        variables_corr_pos = variables_corr_pos*0\n",
        "        variables_corr_neg = variables_corr_pos*0\n",
        "\n",
        "        variables_corr_pos_val = variables_corr_pos_val*0\n",
        "        variables_corr_neg_val = variables_corr_pos_val*0\n",
        "\n",
        "\n",
        "def evaluation(model, X_train, y_train, X_test, y_test, scoring, plot):\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "    \n",
        "    print(\"test set : \")\n",
        "    print(confusion_matrix(y_test, y_pred))\n",
        "    print(classification_report(y_test, y_pred)) \n",
        "    print(\"train set : \")\n",
        "    print(confusion_matrix(y_train, model.predict(X_train))) # ajouter \n",
        "    print(classification_report(y_train, model.predict(X_train) ))\n",
        "\n",
        "    if plot == True:\n",
        "        N, train_score, val_score = learning_curve(model, X_train, y_train, shuffle=True, cv = 4, scoring = scoring, train_sizes = np.linspace(0.1, 1, 6) )\n",
        "\n",
        "        plt.figure(figsize = (10,6))\n",
        "        plt.plot(N, train_score.mean(axis=1), label =\"train_score\")\n",
        "        plt.plot(N, val_score.mean(axis=1), label =\"cross_validation_score\")\n",
        "        plt.legend()\n",
        "    else :\n",
        "        print(\"GRAPHIQUE NON DEMANDE\")\n",
        "\n",
        "# Comme il n'y a pas de valeurs manquantes (à la place il y a un nombre), le seul traitement qu'on fait c'est tranformer\n",
        "# le type de variable (les variables continues deviennent qualitatives)\n",
        "def data_processing(df):\n",
        "    \"\"\" \n",
        "    for i in range(0,len(df.columns)):    \n",
        "        df[df.columns[i]].fillna(100.0, inplace=True) #On remplace les données manquantes par 100\n",
        "    for i in range(0,len(df.columns)):\n",
        "        print(df[df.columns[i]].value_counts(dropna=False))    \n",
        "    \"\"\"\n",
        "    \n",
        "   #Transformation de toutes les variables en facteurs         \n",
        "    for i in range(0,len(df.columns)):\n",
        "        df[df.columns[i]] = df[df.columns[i]].astype('category')\n",
        "    return df.to_numpy() #.as_matrix()\n",
        "\n",
        "\n",
        "def quarantiles(model, data_orig, affichage, save, path):\n",
        "    # position de la dernière variable explicative dans le dataset\n",
        "    nb_var = data_orig.shape[1]-1\n",
        "\n",
        "    # predict sur tous les individus (avec et sans classe IFI+)\n",
        "    tous_probas = model.predict_proba(data_orig.iloc[:,1:nb_var])\n",
        "    df_tous = pd.DataFrame({'IDENT': data_orig.iloc[:,0] , 'PROBA': tous_probas[:,0] })\n",
        "    #df_tous\n",
        "    \n",
        "    # valeurs ordonnées pour diviser après\n",
        "    df_tous=df_tous.sort_values(by='PROBA', ascending=True)\n",
        "    #df_tous\n",
        "    print(df_tous)\n",
        "    \n",
        "    #vérification\n",
        "    print(df_tous['PROBA'].value_counts())\n",
        "\n",
        "    # quarantiles\n",
        "    df_temp =pd.DataFrame( pd.qcut(df_tous['PROBA'],q= 20)  )\n",
        "    print(df_temp)\n",
        "\n",
        "    # ajout par index (IMPORTANTE)\n",
        "    df_tous[\"TRANCHES\"]=pd.DataFrame(df_temp.iloc[:,0].to_numpy(),index= df_temp.index)\n",
        "    #print(df_tous)\n",
        "    \n",
        "    # pour la colonne IFI+ :\n",
        "    # remplissage de la dernière colonne par 2 (VALABLE QUE POUR CE DATA, MODIFIER POUR D'AUTRES)\n",
        "    data_temp_t = data_orig.copy()\n",
        "    # remplacement\n",
        "    data_temp_t[\"Top_mon\"] =  data_temp_t[\"Top_mon\"].replace(1.0,'1')\n",
        "    data_temp_t[\"Top_mon\"] =  data_temp_t[\"Top_mon\"].replace(2.0,'2')\n",
        "    data_all_complet_class = data_temp_t.fillna('2')\n",
        "    #data_all_complet_class\n",
        "\n",
        "    # jointure\n",
        "    ident_class_tous = data_all_complet_class[[\"IDENT\",\"Top_mon\"]]\n",
        "    tableau_resultats = pd.merge(df_tous,ident_class_tous)\n",
        "    #tableau_resultats\n",
        "\n",
        "    # tranches finales\n",
        "    tab_cross_temp = pd.crosstab(tableau_resultats[\"TRANCHES\"],tableau_resultats[\"Top_mon\"])\n",
        "    #print(tab_cross_temp); print(\"-----------------------\")\n",
        "\n",
        "    # création d'une colonne total\n",
        "    tab_cross_temp[\"TOTAL\"]=tab_cross_temp[\"1\"]+tab_cross_temp[\"2\"]\n",
        "    \n",
        "    # affichage\n",
        "    if affichage ==True:        \n",
        "        print(tab_cross_temp)\n",
        "    \n",
        "    # création du tableau final en éliminant la colonne 2\n",
        "    tab_pour_excel = tab_cross_temp.drop([\"2\"], axis=1)\n",
        "    \n",
        "    # enregistrement sous Excel\n",
        "    if save == True:\n",
        "        tab_pour_excel.to_excel(path)\n",
        "\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DDurwydOLm27"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.metrics import f1_score, confusion_matrix, classification_report\n",
        "from sklearn.model_selection import learning_curve, GridSearchCV"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YspyzyxrLm5E"
      },
      "source": [
        ""
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SZXGTwDK5pu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8fafc495-b071-462d-e6d2-8a4cafa4931d"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# test predict individus sans classe\n",
        "data = data_orig.copy()\n",
        "\n",
        "# encodage Onehot sur toutes les données (on évite ainsi les erreurs futures)\n",
        "nb_var = data.shape[1] - 1\n",
        "data_1_22 = pd.get_dummies(data.iloc[:,1:(data.shape[1]-1)], columns=data.columns[1:(data.shape[1]-1)] )\n",
        "data_var_qualitatives_temp =  pd.concat([data[\"IDENT\"], data_1_22, data[\"Top_mon\"]], axis=1)\n",
        "data = data_var_qualitatives_temp\n",
        "#encodage = OneHotEncoder()\n",
        "#encodage.fit(data_processing(data.iloc[:,1:nb_var]))\n",
        "\n",
        "# élimination des individus n'ayant pas de valeur pour la varialbe IFI+\n",
        "\"\"\"IMPORTANT\"\"\"\n",
        "data_sans_nan = data[(data.isnull()).sum(axis=1) == 0]\n",
        "\n",
        "#conversion du type de variable\n",
        "for i in range(1,data_sans_nan.shape[1]):\n",
        "    data_sans_nan.iloc[:,i]=data_sans_nan.iloc[:,i].astype(int)\n",
        "\n",
        "# base de données avec des variables corrélées et avec encodage OneHot\n",
        "data =data_sans_nan\n",
        "\n",
        "nb_var = data.shape[1] - 1\n",
        "train_set, test_set = train_test_split(data, test_size = 0.2, random_state=0 )\n",
        "\n",
        "train_X_s = (train_set.iloc[:,1:nb_var]).to_numpy()\n",
        "train_Y_s = np.asanyarray(train_set.iloc[:,nb_var])\n",
        "\n",
        "test_X_s = (test_set.iloc[:,1:nb_var]).to_numpy()\n",
        "test_Y_s = np.asanyarray(test_set.iloc[:,nb_var])\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pandas/core/indexing.py:1743: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  isetter(ilocs[0], value)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b5zAmSiiW47I",
        "outputId": "4be9c3a3-5714-40d5-c8c4-234900fc5b32"
      },
      "source": [
        "\n",
        "from imblearn.under_sampling import TomekLinks\n",
        "from imblearn.over_sampling import SMOTE"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Dp6BKsHW5FJ",
        "outputId": "6e924c65-ef33-44c2-f514-9315199a958a"
      },
      "source": [
        "# augmentation des données\n",
        "tl = SMOTE()\n",
        "X_resampled, y_resampled = tl.fit_resample(train_X_s[:,:nb_var] , train_Y_s )\n",
        "\n",
        "\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1IOJAsXXOvW",
        "outputId": "58c6512a-e0a2-417d-a509-4fa2e0e81475"
      },
      "source": [
        "print(np.unique(y_resampled, return_counts=True) )\n",
        "np.unique(train_Y_s, return_counts = True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([1, 2]), array([82915, 82915]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([1, 2]), array([18777, 82915]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Toer4zPSXOxw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAotUpZQXO0Q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYWebMY5Q346",
        "outputId": "cf1fdfe7-4a66-4e0d-e0bf-4cce68efda54"
      },
      "source": [
        "#model_MLP = MLP(random_state = 0)\n",
        "#model_MLP.fit(train_X_s, train_Y_s)\n",
        "\n",
        "final_model_MLP = MLPClassifier(random_state=0)\n",
        "evaluation(final_model_MLP , X_resampled, y_resampled, test_X_s, test_Y_s, scoring=\"recall\", plot=False)\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:571: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
            "  % self.max_iter, ConvergenceWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "test set : \n",
            "[[ 1232  3447]\n",
            " [ 2223 18521]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.36      0.26      0.30      4679\n",
            "           2       0.84      0.89      0.87     20744\n",
            "\n",
            "    accuracy                           0.78     25423\n",
            "   macro avg       0.60      0.58      0.59     25423\n",
            "weighted avg       0.75      0.78      0.76     25423\n",
            "\n",
            "train set : \n",
            "[[75822  7093]\n",
            " [ 2821 80094]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.96      0.91      0.94     82915\n",
            "           2       0.92      0.97      0.94     82915\n",
            "\n",
            "    accuracy                           0.94    165830\n",
            "   macro avg       0.94      0.94      0.94    165830\n",
            "weighted avg       0.94      0.94      0.94    165830\n",
            "\n",
            "GRAPHIQUE NON DEMANDE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TB1kkqYLK5r9"
      },
      "source": [
        "model_MLP = MLPClassifier(random_state =0 )\n",
        "param = { }\n",
        "\n",
        "grid_MLP = GridSearchCV(model_MLP, param, cv = 4, scoring = \"recall\", n_jobs=2)\n",
        "resultat_grid_MLP = grid_MLP.fit(train_X_s, train_Y_s)\n",
        "resultat_grid_MLP.best_params_\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7EGiWPpcQkfq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIBrIyqiQkh4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "90rFeHi8QkkI",
        "outputId": "5031830f-faf3-408d-b800-efac0f6e0639"
      },
      "source": [
        "final_model_MLP.get_params "
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method BaseEstimator.get_params of MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(100,), learning_rate='constant',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=200,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=0, shuffle=True, solver='adam',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3jV6RXfVM0z"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}